{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c439bf13",
   "metadata": {},
   "source": [
    "# Download Wikipedia and unzip the bz2 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02012e73",
   "metadata": {},
   "source": [
    "# Cut the file down just to the infoboxes we care about\n",
    "```\n",
    "grep -A 50 -B 50 \"Infobox medical condition (new)\" enwiki-20230820-pages-articles-multistream.xml < medical-condition-box.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ad2e5",
   "metadata": {},
   "source": [
    "# Extract all Symptom <=> Name pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dffc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with open(\"./medical-condition-box.txt\", 'r') as wikipedia_file:\n",
    "    wiki_data = wikipedia_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3774753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "infobox_start_indexes = [m.start() for m in re.finditer(r'Infobox medical condition \\(new\\)', wiki_data)]\n",
    "len(infobox_start_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "curly_bracket_regex = r\"((\\{\\{).*?(\\}\\}))\"\n",
    "curly_bracket_regex = re.compile(curly_bracket_regex)\n",
    "refrence_regex = r\"((&lt;).*?(gt;))\"\n",
    "refrence_regex = re.compile(refrence_regex)\n",
    "info_box_section_regex = r\"\\| symptoms\\s+=\"\n",
    "info_box_section_regex = re.compile(info_box_section_regex)\n",
    "\n",
    "j = 0\n",
    "\n",
    "def clean_wikipedia_string(string):\n",
    "    string = re.sub(refrence_regex, \"\", string)\n",
    "    string = re.sub(curly_bracket_regex, \"\", string)\n",
    "    string = re.sub(info_box_section_regex, \"\", string)\n",
    "    while string.find(\"[[\") != -1:\n",
    "        start_bracket = string.find(\"[[\")\n",
    "        end_bracket = string.find(\"]]\")\n",
    "\n",
    "        bracket_string = string[start_bracket:end_bracket+2]\n",
    "        bracket_text = bracket_string.replace(\"[[\", \"\").replace(\"]]\", \"\")\n",
    "        if \"|\" in bracket_text:\n",
    "            bracket_text = bracket_text.split(\"|\")[-1]\n",
    "\n",
    "        string = string.replace(bracket_string, bracket_text)\n",
    "\n",
    "    return string\n",
    "\n",
    "all_medical_conditions = []\n",
    "for infobox_start_index in infobox_start_indexes:\n",
    "    MAX_CHARACTERS = 5000\n",
    "    info_box_text = wiki_data[infobox_start_index:infobox_start_index+MAX_CHARACTERS]\n",
    "    start_index=0\n",
    "    end_index=0\n",
    "    while True:\n",
    "        next_close = info_box_text[start_index:].find(\"}}\")\n",
    "        next_open = info_box_text[start_index:].find(\"{{\")\n",
    "        if next_open < next_close and next_open != -1:\n",
    "            start_index += next_close + 2\n",
    "        else:\n",
    "            end_index = start_index + next_close\n",
    "            break\n",
    "        \n",
    "    info_box_focused = info_box_text[:end_index]\n",
    "    \n",
    "    provided_info = info_box_focused.split(\"\\n\")\n",
    "    symptoms = [line for line in provided_info if \"| symptoms\" in line]\n",
    "    if len(symptoms) == 1:\n",
    "        symptoms_string = clean_wikipedia_string(symptoms[0]).strip()\n",
    "\n",
    "        if symptoms_string != \"\":\n",
    "            names = [line for line in provided_info if \"| name\" in line]\n",
    "            if len(names) == 1:\n",
    "                name_string = clean_wikipedia_string(names[0])\n",
    "                condition_name = name_string.split(\"=\")[-1]\n",
    "                if condition_name.strip() != \"\":\n",
    "                    all_medical_conditions.append({\"name\" : condition_name, \"symptoms\": symptoms_string})\n",
    "        \n",
    "#     print(\"\\n\\n ========================== \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d1de0",
   "metadata": {},
   "source": [
    "# Prompt Chat GPT to cleanup Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ed98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(\n",
    "  organization='org-B...',\n",
    "  api_key= \"sk-E...\",\n",
    ")\n",
    "\n",
    "def get_prompt(symptoms):\n",
    "    return f\"\"\"Given the brief symptom text, extract a list of basically worded symptoms. Use as few words as possible. Make a list with each symptom on a new line and a dash to start each symptom. Only list the symptoms in the text.\n",
    "\n",
    "SYMPTOMS:\n",
    "{symptoms}\"\"\"\n",
    "\n",
    "def load_dictionary_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_dictionary_to_file(dictionary, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(dictionary, file)\n",
    "\n",
    "CACHE_FILE = \"openai_cache.json\"\n",
    "openai_cache = load_dictionary_from_file(CACHE_FILE)\n",
    "\n",
    "for medical_condition in tqdm(all_medical_conditions):\n",
    "    name_string  = medical_condition[\"name\"]\n",
    "    symptom_string = medical_condition[\"symptoms\"]\n",
    "    \n",
    "    if symptom_string in openai_cache:\n",
    "        continue\n",
    "    else:\n",
    "        prompt = get_prompt(openai_cache)\n",
    "        completion = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": get_prompt(symptom_string)}\n",
    "          ],\n",
    "          temperature=0.0\n",
    "        )\n",
    "        content = completion.choices[0].message.content\n",
    "        openai_cache[symptom_string] = content\n",
    "        \n",
    "        print(\"\")\n",
    "        print(name_string)\n",
    "        print(content)\n",
    "        save_dictionary_to_file(openai_cache, CACHE_FILE)\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": get_prompt(\"'''Acute''': vomiting, abdominal pain, watery diarrhea'''Chronic''': thickened skin, darker skin, cancer\")}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2933d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, medical_condition in enumerate(all_medical_conditions):\n",
    "    symptoms = openai_cache[medical_condition[\"symptoms\"]]\n",
    "    symptoms = list(filter(lambda x: len(x) > 0, map(lambda x: x.replace(\"-\",\"\").strip(), symptoms.split(\"\\n\"))))\n",
    "    symptoms = list(map(lambda x: x.lower(), symptoms))\n",
    "    all_medical_conditions[i][\"symptom_list\"] = symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1425a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common symptoms\n",
    "symptom_frequency = {}\n",
    "\n",
    "for medical_condition in all_medical_conditions:\n",
    "    for symptom in medical_condition[\"symptom_list\"]:\n",
    "        if symptom not in symptom_frequency:\n",
    "            symptom_frequency[symptom] = 0\n",
    "        symptom_frequency[symptom] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(list(symptom_frequency.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec10d6",
   "metadata": {},
   "source": [
    "# Cleanup further by combining similar symptoms with an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "symptom_names = list(symptom_frequency.keys())\n",
    "symptom_names_prompt_engineered = [f\"Symptoms {symptom_name}\" for symptom_name in symptom_names]\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "model = AutoModel.from_pretrained('intfloat/e5-large-v2')\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "    # normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n",
    "    \n",
    "embeddings = get_embeddings(symptom_names_prompt_engineered)\n",
    "# scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "# print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f620a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ed459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sim_matrix = (embeddings @ embeddings.T).detach().numpy()\n",
    "sim_matrix = np.triu(sim_matrix)\n",
    "sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.detach().numpy()\n",
    "embeddings_map = {symptom_names[i]:embeddings[i] for i in range(len(symptom_names))} # Text => Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03838d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalency_matrix = np.zeros_like(sim_matrix)\n",
    "for i in range(sim_matrix.shape[0]):\n",
    "    sim_matrix[i][sim_matrix[i] > 0.999] = 0\n",
    "    equivalency_matrix[i][(sim_matrix[i] > 0.97)] = 1\n",
    "#     match_count = sim_matrix[i][close_enough_mask].shape[0]\n",
    "#     equivalency_matrix[i] = sim_matrix[i][(np.argsort(-sim_matrix[i]) < match_count).astype(np.int32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ecb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "SymptomG = nx.Graph()\n",
    "\n",
    "for symptom_name in symptom_names:\n",
    "    SymptomG.add_node(symptom_name)\n",
    "\n",
    "xs,ys = np.where(equivalency_matrix == 1)\n",
    "for i in range(len(xs)):\n",
    "    SymptomG.add_edge(symptom_names[xs[i]], symptom_names[ys[i]])\n",
    "for a in range(len(symptom_names)):\n",
    "    for b in range(len(symptom_names)):\n",
    "        if a > b:\n",
    "            continue\n",
    "            \n",
    "        WORDS_TO_INDICATE_EQUIVALENCY_REGARDLESS_OF_EMBEDDING = [\"fever\", \"headache\"]\n",
    "        for word in WORDS_TO_INDICATE_EQUIVALENCY_REGARDLESS_OF_EMBEDDING:\n",
    "            if word in symptom_names[a] and word in symptom_names[b]:\n",
    "                SymptomG.add_edge(symptom_names[a], symptom_names[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa36377",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_simplifier_map = {}\n",
    "for comp in nx.connected_components(SymptomG):\n",
    "    shortest = \"\"\n",
    "    shortest_len = 999\n",
    "    for symptom in comp:\n",
    "        if len(symptom) < shortest_len:\n",
    "            shortest_len = len(symptom)\n",
    "            shortest = symptom\n",
    "            \n",
    "    symptom_simplifier_map[shortest] = comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1621ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for medical_condition in all_medical_conditions:\n",
    "    new_symptom_list = set()\n",
    "    for symptom in medical_condition[\"symptom_list\"]:\n",
    "        for shortest, symptom_set in symptom_simplifier_map.items():\n",
    "            if symptom in symptom_set:\n",
    "                new_symptom_list.add(shortest)\n",
    "                \n",
    "    medical_condition[\"condensed_symptom_list\"] = list(new_symptom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common symptoms\n",
    "condensed_symptom_frequency = {}\n",
    "\n",
    "for medical_condition in all_medical_conditions:\n",
    "    for symptom in medical_condition[\"condensed_symptom_list\"]:\n",
    "        if symptom not in condensed_symptom_frequency:\n",
    "            condensed_symptom_frequency[symptom] = 0\n",
    "        condensed_symptom_frequency[symptom] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce86c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all common symptoms embeddings (This is inefficient because we already computed them earlier)\n",
    "common_symptom_names = [s for s,o in condensed_symptom_frequency.items() if o > 2]\n",
    "uncommon_symptom_names = [s for s,o in condensed_symptom_frequency.items() if o <= 2]\n",
    "common_symptom_names_prompt_engineered = [f\"Symptom {symp}\" for symp in common_symptom_names]\n",
    "common_embeddings = get_embeddings(common_symptom_names_prompt_engineered).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a symptom is rare, combine it with something bigger, else cut it out\n",
    "SIM_CUTOFF = 0.92\n",
    "uncommon_to_common_map = {}\n",
    "\n",
    "for symptom, relevance in condensed_symptom_frequency.items():\n",
    "    if relevance <= 2:\n",
    "        symp_embedding = embeddings_map[symptom]\n",
    "        sim_matrix = (symp_embedding @ common_embeddings.T)\n",
    "        sim_matrix[sim_matrix < SIM_CUTOFF] = 0\n",
    "        sim_matrix[sim_matrix > 0.999] = 0\n",
    "        highest_index = np.argsort(-sim_matrix)[0]\n",
    "        if sim_matrix[highest_index] != 0:\n",
    "            uncommon_to_common_map[symptom] = common_symptom_names[highest_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for medical_condition in all_medical_conditions:\n",
    "    new_symptom_list = set()\n",
    "    for symptom in medical_condition[\"condensed_symptom_list\"]:\n",
    "        if symptom in common_symptom_names:\n",
    "            new_symptom_list.add(symptom)\n",
    "        else:\n",
    "            if symptom in uncommon_to_common_map:\n",
    "                new_symptom_list.add(uncommon_to_common_map[symptom])\n",
    "    \n",
    "    medical_condition[\"condensed_symptom_list2\"] = list(new_symptom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common symptoms\n",
    "condensed_symptom_frequency2 = {}\n",
    "\n",
    "for medical_condition in all_medical_conditions:\n",
    "    for symptom in medical_condition[\"condensed_symptom_list2\"]:\n",
    "        if symptom not in condensed_symptom_frequency2:\n",
    "            condensed_symptom_frequency2[symptom] = 0\n",
    "        condensed_symptom_frequency2[symptom] += 1\n",
    "        \n",
    "condensed_symptom_frequency2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50af25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hq_medical_conditions = [mc for mc in all_medical_conditions if len(mc[\"condensed_symptom_list2\"]) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ac617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "medical_condition_names = [mc[\"name\"] for mc in hq_medical_conditions]\n",
    "\n",
    "G = nx.Graph()\n",
    "for i, medical_condition in enumerate(hq_medical_conditions):\n",
    "    G.add_nodes_from([(medical_condition[\"name\"], {\"name\": medical_condition[\"name\"], \"type\": \"MedicalCondition\"})])\n",
    "\n",
    "for symptom in condensed_symptom_frequency2.keys():\n",
    "    G.add_nodes_from([(symptom, {\"name\": symptom.strip(), \"type\": \"Symptom\"})])\n",
    "    \n",
    "for i, medical_condition in enumerate(hq_medical_conditions):\n",
    "    for symptom in medical_condition[\"condensed_symptom_list2\"]:\n",
    "        G.add_edge(medical_condition[\"name\"], symptom)\n",
    "        \n",
    "with open(\"md-symptom.gexf\", 'w') as f:\n",
    "    f.write(\"\\n\".join(list(nx.generate_gexf(G))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b790038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dictionary_to_file(hq_medical_conditions, \"high_quality_symptoms.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391533d2",
   "metadata": {},
   "source": [
    "# Prompt Chat GPT for Medical Condition prevelence and Symtom Chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8cd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(\n",
    "  organization='org-B...',\n",
    "  api_key= \"sk-E...\",\n",
    ")\n",
    "\n",
    "def get_symp_prob_prevelance_prompt(symptom_list, name):\n",
    "    symptom_list_str = \"\\n\".join([f\"    - {symp}: ??.??\" for symp in symptom_list])\n",
    "    return f\"\"\"Given the following medical condition, provide a quick one sentence summary. Given the list of symptoms, provide the percentage chance of experiencing the symptom given that you have the illness. Make sure to use the format below. Ensure the symptom values only contain digits (no \"%\" symbol) and make it out of 100. Please also provide prevalence by stating the percentage chance of an American having this illness in a year (Based out of 100). THE VALUES OF prevalence and symptoms SHOULD ONLY BE NUMBERS!!!\n",
    "name: \"{name}\"\n",
    "summary:\n",
    "symptoms:\n",
    "{symptom_list_str}\n",
    "prevalence: ??.?\"\"\"\n",
    "\n",
    "def load_dictionary_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_dictionary_to_file(dictionary, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(dictionary, file)\n",
    "\n",
    "hq_medical_conditions = load_dictionary_from_file(\"high_quality_symptoms.pkl\")\n",
    "        \n",
    "CACHE_FILE = \"openai_cache_2.json\"\n",
    "openai_cache = load_dictionary_from_file(CACHE_FILE)\n",
    "\n",
    "for medical_condition in tqdm(hq_medical_conditions):\n",
    "    name_string  = medical_condition[\"name\"]\n",
    "    symptom_list = medical_condition[\"condensed_symptom_list2\"] + [\"death\"]\n",
    "    prompt =  get_symp_prob_prevelance_prompt(symptom_list, name_string)\n",
    "    \n",
    "    if prompt in openai_cache:\n",
    "        print(\"Skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        completion = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant which response in YAML.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ],\n",
    "          temperature=0.0\n",
    "        )\n",
    "        content = completion.choices[0].message.content\n",
    "        openai_cache[prompt] = content\n",
    "        \n",
    "        print(\"\")\n",
    "        print(name_string)\n",
    "        print(content)\n",
    "        save_dictionary_to_file(openai_cache, CACHE_FILE)\n",
    "        \n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932de5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def clean_str(string):\n",
    "    return (''.join(e for e in string if e.isalnum())).lower().strip()\n",
    "\n",
    "for mc in hq_medical_conditions:\n",
    "    name_string  = mc[\"name\"]\n",
    "    symptom_list = mc[\"condensed_symptom_list2\"] + [\"death\"]\n",
    "    prompt = get_symp_prob_prevelance_prompt(symptom_list, name_string)\n",
    "    response_yaml = yaml.safe_load(openai_cache[prompt])\n",
    "    if \"?\" in str(response_yaml[\"prevalence\"]):\n",
    "        mc[\"prevalence\"] = 0.001\n",
    "    else:\n",
    "        mc[\"prevalence\"] = float(response_yaml[\"prevalence\"])\n",
    "    mc[\"summary\"] = response_yaml[\"summary\"]\n",
    "    mc[\"name\"] = mc[\"name\"].strip()\n",
    "    \n",
    "    # Parse out symptom list\n",
    "    symptom_dict = {}\n",
    "    death_prev = 0\n",
    "    for symptom in mc[\"condensed_symptom_list2\"]:\n",
    "        if type(response_yaml[\"symptoms\"]) == list:\n",
    "            found = False\n",
    "            for res_symptom in response_yaml[\"symptoms\"]:\n",
    "                try:\n",
    "                    symp = list(res_symptom.keys())[0]\n",
    "                    prev = list(res_symptom.values())[0]\n",
    "                    \n",
    "                    if clean_str(symp) == \"death\":\n",
    "                        death_prev = prev\n",
    "                    \n",
    "                    if clean_str(symp) == clean_str(symptom):\n",
    "                        symptom_dict[symptom] = float(prev)\n",
    "                        found = True\n",
    "                        break\n",
    "                    \n",
    "                except:\n",
    "                    print(response_yaml)\n",
    "            for res_symptom in response_yaml[\"symptoms\"]:\n",
    "                symp = list(res_symptom.keys())[0]\n",
    "                prev = list(res_symptom.values())[0]\n",
    "                if clean_str(symp) == \"death\":\n",
    "                    death_prev = prev\n",
    "                    \n",
    "            if (found == False):\n",
    "                print(symptom)\n",
    "                print(response_yaml)\n",
    "        elif type(response_yaml[\"symptoms\"]) == dict:\n",
    "            found = False\n",
    "            for symp, prev in response_yaml[\"symptoms\"].items():\n",
    "                try:\n",
    "                    if clean_str(symp) == clean_str(symptom):\n",
    "                        symptom_dict[symptom] = float(prev)\n",
    "                        death_prev = float(prev)\n",
    "                        found = True\n",
    "                        break\n",
    "                    \n",
    "                except:\n",
    "                    print(response_yaml)\n",
    "                    \n",
    "            for symp, prev in response_yaml[\"symptoms\"].items():\n",
    "                if clean_str(symp) == \"death\":\n",
    "                    death_prev = prev\n",
    "            if (found == False):\n",
    "                print(symptom)\n",
    "                print(response_yaml)\n",
    "                \n",
    "    mc[\"symptom_prevelances\"] = symptom_dict\n",
    "    mc[\"mortality_chance\"] = float(death_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hq_medical_conditions[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ae2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symptoms = set()\n",
    "for symptom_list in [list(mc[\"symptom_prevelances\"].keys()) for mc in hq_medical_conditions]:\n",
    "    all_symptoms.update(symptom_list)\n",
    "    \n",
    "all_symptoms = sorted(list(all_symptoms))\n",
    "all_symptoms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "medical_condition_names = [mc[\"name\"] for mc in hq_medical_conditions]\n",
    "\n",
    "G = nx.Graph()\n",
    "for i, medical_condition in enumerate(hq_medical_conditions):\n",
    "    G.add_nodes_from([(medical_condition[\"name\"], {\"name\": medical_condition[\"name\"].strip(), \"type\": \"MedicalCondition\", \"mortality_rate\": float(medical_condition[\"mortality_chance\"]) + 0.0000001, \"prevalence\": medical_condition[\"prevalence\"]})])\n",
    "\n",
    "for symptom in all_symptoms:\n",
    "    G.add_nodes_from([(symptom, {\"name\": symptom.strip(), \"type\": \"Symptom\"})])\n",
    "    \n",
    "for i, medical_condition in enumerate(hq_medical_conditions):\n",
    "    for symptom, prevalence in medical_condition[\"symptom_prevelances\"].items():\n",
    "        G.add_edge(medical_condition[\"name\"], symptom, prevalence=prevalence)\n",
    "        \n",
    "with open(\"md-symptom.gexf\", 'w') as f:\n",
    "    f.write(\"\\n\".join(list(nx.generate_gexf(G))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa01a11",
   "metadata": {},
   "source": [
    "# Test Bayesian Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416384f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "all_symptoms = list(set(all_symptoms))\n",
    "symptom_names_prompt_engineered = [f\"Symptoms {symptom_name}\" for symptom_name in all_symptoms]\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "model = AutoModel.from_pretrained('intfloat/e5-large-v2')\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "    # normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n",
    "    \n",
    "embeddings = get_embeddings(symptom_names_prompt_engineered)\n",
    "similarity_matrix = embeddings @ embeddings.T\n",
    "similarity_matrix = similarity_matrix.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('md-symptom-sim-mat.npy', similarity_matrix)\n",
    "similarity_matrix = np.load('md-symptom-sim-mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medical_condition_from_symptoms(g, symptoms, sim_matrix=None):\n",
    "    symptom_nodes = []\n",
    "    possible_medical_conditions = []\n",
    "    for symptom in symptoms:\n",
    "        if g.has_node(symptom):\n",
    "            # TODO: Assert the node that is found is a symptom node\n",
    "            symptom_nodes.append(g.nodes[symptom][\"name\"])\n",
    "            neighbor_ids = g.neighbors(symptom)\n",
    "            for neighbor_id in neighbor_ids:\n",
    "                possible_medical_conditions.append(g.nodes[neighbor_id])\n",
    "\n",
    "    # Initialize each chance to 1\n",
    "    mc_chance = {mc[\"name\"]:mc[\"prevalence\"]/100 for mc in possible_medical_conditions}\n",
    "\n",
    "    # Check each edge\n",
    "    for mc in possible_medical_conditions:\n",
    "        for symp in symptom_nodes:\n",
    "            edge_data = g.get_edge_data(mc[\"name\"], symp)\n",
    "            if edge_data != None:\n",
    "                mc_chance[mc[\"name\"]] *= edge_data[\"prevalence\"] / 100\n",
    "            else:\n",
    "                mc_chance[mc[\"name\"]] *= 0.01\n",
    "\n",
    "    # Normalize\n",
    "    chance_sum = 0\n",
    "    for symp, chance in mc_chance.items():\n",
    "        chance_sum += chance\n",
    "\n",
    "    for symp, chance in mc_chance.items():\n",
    "        mc_chance[symp] = chance / chance_sum\n",
    "        \n",
    "    return sorted(mc_chance.items(), key=lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b66593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement similarity embeddings matrix\n",
    "get_medical_condition_from_symptoms(G, [\"fever\", \"itch\", \"headache\"], sim_matrix=similarity_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
